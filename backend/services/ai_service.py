from typing import Dict, Any, List, Optional
import json
import re
import sys
import os
import uuid
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from openai import OpenAI

from config import Config
from .rag_service import RAGService
from .session_service import SessionService

class AIService:
    def __init__(self):
        """åˆå§‹åŒ–AIæœåŠ¡"""
        print("ğŸ¤– åˆå§‹åŒ–AIæœåŠ¡...")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['OPENAI_API_KEY'] = Config.OPENAI_API_KEY
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        try:
            self.openai_client = OpenAI(
                api_key=Config.OPENAI_API_KEY,
                base_url=Config.OPENAI_BASE_URL
            )
            print("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.openai_client = None
            
        # åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
        try:
            self.deepseek_client = OpenAI(
                api_key=Config.DEEPSEEK_API_KEY,
                base_url=Config.DEEPSEEK_BASE_URL
            )
            print("âœ… DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.deepseek_client = None
        
        # åˆå§‹åŒ–æœåŠ¡ç»„ä»¶
        self.rag_service = RAGService()
        self.session_service = SessionService()
        
        print("âœ… AIæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def _call_llm(self, messages: List[Dict[str, str]], use_deepseek: bool = False, 
                  temperature: float = 0.7, max_tokens: int = 2000) -> Dict[str, Any]:
        """è°ƒç”¨å¤§æ¨¡å‹"""
        try:
            if use_deepseek and self.deepseek_client:
                client = self.deepseek_client
                model = Config.DEEPSEEK_MODEL
                model_name = "DeepSeek"
            elif self.openai_client:
                client = self.openai_client
                model = Config.OPENAI_MODEL
                model_name = "OpenAI"
            else:
                return {
                    "success": False,
                    "error": "æ²¡æœ‰å¯ç”¨çš„AIå®¢æˆ·ç«¯",
                    "model_used": "æ— "
                }
            
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            return {
                "success": True,
                "content": response.choices[0].message.content,
                "model_used": model_name,
                "tokens_used": response.usage.total_tokens if response.usage else 0
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"LLMè°ƒç”¨å¤±è´¥: {str(e)}",
                "model_used": model_name if 'model_name' in locals() else "æœªçŸ¥"
            }
    
    def _build_context_aware_messages(self, question: str, session_id: str = None, 
                                    relevant_docs: List[Dict] = None, document_ids: List[str] = None) -> List[Dict[str, str]]:
        """æ„å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ¶ˆæ¯åˆ—è¡¨"""
        messages = []
        
        # ç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å­¦ä¹ åŠ©æ‰‹ï¼Œæ“…é•¿åŸºäºæ–‡æ¡£å†…å®¹å’Œå¯¹è¯å†å²æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚

æ ¸å¿ƒèƒ½åŠ›ï¼š
1. **æ–‡æ¡£ç†è§£**ï¼šæ·±åº¦åˆ†æç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£ï¼Œæå–å…³é”®ä¿¡æ¯
2. **ä¸Šä¸‹æ–‡è®°å¿†**ï¼šè®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œæä¾›è¿è´¯çš„å¤šè½®å¯¹è¯ä½“éªŒ
3. **æ™ºèƒ½æ¨ç†**ï¼šç»“åˆæ–‡æ¡£å†…å®¹å’Œå¯¹è¯å†å²ï¼Œè¿›è¡Œæ·±å…¥åˆ†æå’Œæ¨ç†
4. **å­¦ä¹ è¾…å¯¼**ï¼šå¸®åŠ©ç”¨æˆ·ç†è§£æ¦‚å¿µã€ç”Ÿæˆæ€»ç»“ã€åˆ¶å®šå­¦ä¹ è®¡åˆ’

å›ç­”è§„åˆ™ï¼š
- å¦‚æœæœ‰ç›¸å…³æ–‡æ¡£ï¼Œä¼˜å…ˆåŸºäºæ–‡æ¡£å†…å®¹å›ç­”ï¼Œå¹¶æ˜ç¡®å¼•ç”¨æ¥æº
- è®°ä½ç”¨æˆ·ä¹‹å‰é—®è¿‡çš„é—®é¢˜ï¼Œé¿å…é‡å¤è§£é‡Šå·²çŸ¥æ¦‚å¿µ
- å¦‚æœç”¨æˆ·é—®é¢˜ä¸ä¹‹å‰çš„å¯¹è¯ç›¸å…³ï¼Œè¦ä½“ç°å‡ºè¿ç»­æ€§
- åœ¨æ²¡æœ‰æ–‡æ¡£æ”¯æŒæ—¶ï¼Œè¯šå®è¯´æ˜å¹¶æä¾›ä¸€èˆ¬æ€§å»ºè®®
- ä¿æŒå›ç­”çš„å‡†ç¡®æ€§ã€æ¸…æ™°æ€§å’Œæœ‰ç”¨æ€§
- ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€è¦ä¸“ä¸šä½†æ˜“æ‡‚

ç‰¹åˆ«æ³¨æ„ï¼š
- ç†è§£ç”¨æˆ·é—®é¢˜çš„ä¸Šä¸‹æ–‡èƒŒæ™¯
- é€‚å½“å¼•ç”¨ä¹‹å‰çš„å¯¹è¯å†…å®¹
- æä¾›å…·æœ‰è¿è´¯æ€§çš„å›ç­”"""

        messages.append({"role": "system", "content": system_prompt})
        
        # æ·»åŠ å†å²å¯¹è¯ä¸Šä¸‹æ–‡
        if session_id:
            historical_messages = self.session_service.get_context_for_llm(session_id)
            if historical_messages:
                # åœ¨ç³»ç»Ÿæ¶ˆæ¯åæ·»åŠ å†å²å¯¹è¯
                messages.extend(historical_messages)
        
        # æ„å»ºå½“å‰é—®é¢˜çš„æ¶ˆæ¯
        if relevant_docs:
            # æœ‰ç›¸å…³æ–‡æ¡£çš„æƒ…å†µ
            context_parts = []
            for i, doc in enumerate(relevant_docs, 1):
                source = doc["metadata"].get("source", f"æ–‡æ¡£{i}")
                content = doc["content"]
                context_parts.append(f"ã€æ–‡æ¡£{i}: {source}ã€‘\n{content}")
            
            context = "\n\n".join(context_parts)
            
            user_message = f"""è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”æˆ‘çš„é—®é¢˜ï¼š

=== ç›¸å…³æ–‡æ¡£å†…å®¹ ===
{context}

=== æˆ‘çš„é—®é¢˜ ===
{question}

è¯·æ ¹æ®ä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯¦ç»†è§£é‡Šï¼›å¦‚æœæ²¡æœ‰ç›´æ¥ç›¸å…³çš„ä¿¡æ¯ï¼Œè¯·è¯´æ˜å¹¶æä¾›ä¸€èˆ¬æ€§çš„å»ºè®®ã€‚"""
        else:
            # æ²¡æœ‰ç›¸å…³æ–‡æ¡£çš„æƒ…å†µ
            if document_ids and len(document_ids) > 0:
                # ç»‘å®šäº†æ–‡æ¡£ä½†æ²¡æ‰¾åˆ°ç›¸å…³å†…å®¹
                user_message = f"""æˆ‘çš„é—®é¢˜æ˜¯ï¼š{question}

æ³¨æ„ï¼šåœ¨ç»‘å®šçš„ {len(document_ids)} ä¸ªæ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚è¯·åŸºäºä½ çš„çŸ¥è¯†å›ç­”é—®é¢˜ï¼Œæˆ–å»ºè®®æ£€æŸ¥æ–‡æ¡£å†…å®¹æ˜¯å¦åŒ…å«ç›¸å…³ä¿¡æ¯ã€‚"""
            else:
                # ç”¨æˆ·ä¸»åŠ¨é€‰æ‹©ä¸ç»‘å®šæ–‡æ¡£
                user_message = f"""æˆ‘çš„é—®é¢˜æ˜¯ï¼š{question}

æ³¨æ„ï¼šå½“å‰å¤„äºçº¯å¤§æ¨¡å‹å›ç­”æ¨¡å¼ï¼Œæ²¡æœ‰ç»‘å®šä»»ä½•æ–‡æ¡£ã€‚æˆ‘å°†åŸºäºæˆ‘çš„è®­ç»ƒçŸ¥è¯†ä¸ºä½ å›ç­”é—®é¢˜ã€‚"""
        
        messages.append({"role": "user", "content": user_message})
        
        return messages
    
    def answer_question(self, question: str, use_deepseek: bool = False, session_id: str = None, document_ids: List[str] = None) -> Dict[str, Any]:
        """æ™ºèƒ½é—®ç­”ï¼ˆæ”¯æŒä¸Šä¸‹æ–‡å’Œæ–‡æ¡£æ£€ç´¢ï¼‰"""
        try:
            # å¦‚æœæ²¡æœ‰æä¾›session_idï¼Œç”Ÿæˆä¸€ä¸ª
            if not session_id:
                session_id = str(uuid.uuid4())
            
            # æ ¹æ®æ˜¯å¦æŒ‡å®šæ–‡æ¡£IDæ¥å†³å®šæ˜¯å¦ä½¿ç”¨æ–‡æ¡£
            if document_ids and len(document_ids) > 0:
                # æœç´¢æŒ‡å®šæ–‡æ¡£çš„å†…å®¹ï¼ˆæ”¯æŒå¤šä¸ªæ–‡æ¡£ï¼‰
                relevant_docs = self._search_in_multiple_documents(question, document_ids, k=5)
            else:
                # ä¸ä½¿ç”¨ä»»ä½•æ–‡æ¡£ï¼Œçº¯å¤§æ¨¡å‹å›ç­”
                relevant_docs = []
            
            sources = []
            if relevant_docs:
                for doc in relevant_docs:
                    source_info = {
                        "content": doc["content"][:200] + "..." if len(doc["content"]) > 200 else doc["content"],
                        "filename": doc["metadata"].get("source", ""),
                        "score": doc.get("score", 0)
                    }
                    sources.append(source_info)
            
            # æ„å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ¶ˆæ¯
            messages = self._build_context_aware_messages(question, session_id, relevant_docs, document_ids)
            
            # è°ƒç”¨LLM
            result = self._call_llm(messages, use_deepseek, temperature=0.3)
            
            if not result["success"]:
                return result
            
            # ä¿å­˜å¯¹è¯åˆ°ä¼šè¯å†å²
            self.session_service.add_conversation(
                session_id=session_id,
                question=question,
                answer=result["content"],
                model_used=result["model_used"],
                sources=sources
            )
            
            return {
                "success": True,
                "answer": result["content"],
                "sources": sources,
                "model_used": result["model_used"],
                "has_context": len(relevant_docs) > 0,
                "session_id": session_id,
                "tokens_used": result.get("tokens_used", 0),
                "context_used": len(self.session_service.get_conversation_history(session_id)) > 1
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"é—®ç­”å¤„ç†å¤±è´¥: {str(e)}",
                "session_id": session_id
            }
    
    def generate_summary(self, documents: List[Dict[str, Any]], use_deepseek: bool = False) -> Dict[str, Any]:
        """ç”Ÿæˆæ–‡æ¡£æ€»ç»“"""
        try:
            if not documents:
                return {
                    "success": False,
                    "error": "æ²¡æœ‰æä¾›æ–‡æ¡£"
                }
            
            # åˆå¹¶æ–‡æ¡£å†…å®¹
            content_parts = []
            sources = []
            
            for doc in documents:
                content_parts.append(doc["content"])
                sources.append({
                    "filename": doc["metadata"].get("source", ""),
                    "content_preview": doc["content"][:100] + "..." if len(doc["content"]) > 100 else doc["content"]
                })
            
            combined_content = "\n\n".join(content_parts)
            
            # æ„å»ºæ€»ç»“æ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£æ€»ç»“ä¸“å®¶ã€‚è¯·ä¸ºç”¨æˆ·ç”Ÿæˆé«˜è´¨é‡çš„æ–‡æ¡£æ€»ç»“ã€‚

æ€»ç»“è¦æ±‚ï¼š
1. **ç»“æ„æ¸…æ™°**ï¼šä½¿ç”¨æ˜ç¡®çš„æ ‡é¢˜å’Œå±‚æ¬¡ç»“æ„
2. **å†…å®¹å®Œæ•´**ï¼šæ¶µç›–æ–‡æ¡£çš„ä¸»è¦è§‚ç‚¹å’Œå…³é”®ä¿¡æ¯
3. **é€»è¾‘åˆç†**ï¼šæŒ‰ç…§é€»è¾‘é¡ºåºç»„ç»‡å†…å®¹
4. **ç®€æ´æ˜äº†**ï¼šå»é™¤å†—ä½™ï¼Œçªå‡ºè¦ç‚¹
5. **æ˜“äºç†è§£**ï¼šä½¿ç”¨æ¸…æ™°çš„è¯­è¨€è¡¨è¾¾

æ€»ç»“æ ¼å¼ï¼š
- ä½¿ç”¨ä¸­æ–‡æ’°å†™
- é‡‡ç”¨markdownæ ¼å¼
- åŒ…å«ä¸»è¦ç« èŠ‚å’Œè¦ç‚¹
- é€‚å½“ä½¿ç”¨åˆ—è¡¨å’Œå¼ºè°ƒ"""
                },
                {
                    "role": "user",
                    "content": f"""è¯·ä¸ºä»¥ä¸‹æ–‡æ¡£å†…å®¹ç”Ÿæˆè¯¦ç»†çš„æ€»ç»“ï¼š

{combined_content}

è¯·ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„æ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡æ¡£æ¦‚è¿°
2. ä¸»è¦å†…å®¹è¦ç‚¹
3. å…³é”®ä¿¡æ¯æå–
4. æ€»ç»“æ€§è§‚ç‚¹"""
                }
            ]
            
            # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“
            result = self._call_llm(messages, use_deepseek, temperature=0.3, max_tokens=3000)
            
            if not result["success"]:
                return result
            
            return {
                "success": True,
                "summary": result["content"],
                "sources": sources,
                "model_used": result["model_used"],
                "document_count": len(documents)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"æ€»ç»“ç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    def generate_quiz(self, documents: List[Dict[str, Any]], question_count: int = 5, 
                     use_deepseek: bool = False) -> Dict[str, Any]:
        """ç”Ÿæˆç»ƒä¹ é¢˜"""
        try:
            if not documents:
                return {
                    "success": False,
                    "error": "æ²¡æœ‰æä¾›æ–‡æ¡£"
                }
            
            # åˆå¹¶æ–‡æ¡£å†…å®¹
            content_parts = []
            for doc in documents:
                content_parts.append(doc["content"])
            
            combined_content = "\n\n".join(content_parts)
            
            messages = [
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™è‚²è¯„ä¼°ä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®å­¦ä¹ ææ–™ç”Ÿæˆé«˜è´¨é‡çš„ç»ƒä¹ é¢˜ã€‚

é¢˜ç›®è¦æ±‚ï¼š
1. **éš¾åº¦é€‚ä¸­**ï¼šæ—¢è¦æœ‰ä¸€å®šæŒ‘æˆ˜æ€§ï¼Œåˆè¦ç¡®ä¿å¯ä»¥è§£ç­”
2. **ç±»å‹å¤šæ ·**ï¼šåŒ…å«é€‰æ‹©é¢˜ã€åˆ¤æ–­é¢˜ã€ç®€ç­”é¢˜ç­‰
3. **è¦†ç›–å…¨é¢**ï¼šæ¶µç›–æ–‡æ¡£çš„ä¸»è¦çŸ¥è¯†ç‚¹
4. **è¡¨è¿°æ¸…æ™°**ï¼šé¢˜ç›®å’Œé€‰é¡¹è¡¨è¿°å‡†ç¡®ã€æ— æ­§ä¹‰
5. **ç­”æ¡ˆå‡†ç¡®**ï¼šæä¾›æ­£ç¡®ç­”æ¡ˆå’Œè¯¦ç»†è§£é‡Š

è¿”å›æ ¼å¼ï¼š
- ä½¿ç”¨ä¸¥æ ¼çš„JSONæ ¼å¼
- æ¯é“é¢˜åŒ…å«ï¼šé¢˜ç›®ã€ç±»å‹ã€é€‰é¡¹ï¼ˆå¦‚é€‚ç”¨ï¼‰ã€æ­£ç¡®ç­”æ¡ˆã€è§£é‡Š
- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«è§£æ"""
                },
                {
                    "role": "user",
                    "content": f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆ {question_count} é“ç»ƒä¹ é¢˜ï¼š

{combined_content}

è¯·ç”ŸæˆJSONæ ¼å¼çš„ç»ƒä¹ é¢˜ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
    "questions": [
        {{
            "id": 1,
            "type": "choice",
            "question": "é¢˜ç›®å†…å®¹",
            "options": ["A. é€‰é¡¹1", "B. é€‰é¡¹2", "C. é€‰é¡¹3", "D. é€‰é¡¹4"],
            "correct_answer": "A",
            "explanation": "ç­”æ¡ˆè§£é‡Š"
        }},
        {{
            "id": 2,
            "type": "judge",
            "question": "åˆ¤æ–­é¢˜å†…å®¹",
            "correct_answer": "true",
            "explanation": "ç­”æ¡ˆè§£é‡Š"
        }},
        {{
            "id": 3,
            "type": "short_answer",
            "question": "ç®€ç­”é¢˜å†…å®¹",
            "correct_answer": "å‚è€ƒç­”æ¡ˆ",
            "explanation": "ç­”æ¡ˆè¦ç‚¹"
        }}
    ]
}}

æ³¨æ„ï¼šè¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œé¢˜ç›®ç±»å‹åŒ…æ‹¬choiceï¼ˆé€‰æ‹©é¢˜ï¼‰ã€judgeï¼ˆåˆ¤æ–­é¢˜ï¼‰ã€short_answerï¼ˆç®€ç­”é¢˜ï¼‰ã€‚"""
                }
            ]
            
            result = self._call_llm(messages, use_deepseek, temperature=0.5, max_tokens=3000)
            
            if not result["success"]:
                return result
            
            # å°è¯•è§£æJSON
            try:
                quiz_data = json.loads(result["content"])
                if "questions" not in quiz_data:
                    raise ValueError("è¿”å›æ•°æ®æ ¼å¼é”™è¯¯")
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
                content = result["content"]
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    quiz_data = json.loads(json_match.group())
                else:
                    return {
                        "success": False,
                        "error": "æ— æ³•è§£æç”Ÿæˆçš„ç»ƒä¹ é¢˜æ ¼å¼"
                    }
            
            return {
                "success": True,
                "quiz": quiz_data,
                "model_used": result["model_used"],
                "question_count": len(quiz_data.get("questions", []))
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"ç»ƒä¹ é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    def generate_study_plan(self, documents: List[Dict[str, Any]], difficulty: str = "medium", 
                           use_deepseek: bool = False) -> Dict[str, Any]:
        """ç”Ÿæˆå­¦ä¹ è®¡åˆ’"""
        try:
            if not documents:
                return {
                    "success": False,
                    "error": "æ²¡æœ‰æä¾›æ–‡æ¡£"
                }
            
            # åˆå¹¶æ–‡æ¡£å†…å®¹
            content_parts = []
            for doc in documents:
                content_parts.append(doc["content"])
            
            combined_content = "\n\n".join(content_parts)
            
            difficulty_map = {
                "easy": "åˆçº§æ°´å¹³ï¼Œé€‚åˆå…¥é—¨å­¦ä¹ ",
                "medium": "ä¸­çº§æ°´å¹³ï¼Œæœ‰ä¸€å®šåŸºç¡€",
                "hard": "é«˜çº§æ°´å¹³ï¼Œéœ€è¦æ·±å…¥æŒæ¡"
            }
            
            difficulty_desc = difficulty_map.get(difficulty, "ä¸­çº§æ°´å¹³")
            
            messages = [
                {
                    "role": "system",
                    "content": f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦ä¹ è§„åˆ’å¸ˆï¼Œæ“…é•¿ä¸ºå­¦ä¹ è€…åˆ¶å®šä¸ªæ€§åŒ–çš„å­¦ä¹ è®¡åˆ’ã€‚

å­¦ä¹ è®¡åˆ’è¦æ±‚ï¼š
1. **ç›®æ ‡æ˜ç¡®**ï¼šè®¾å®šæ¸…æ™°çš„å­¦ä¹ ç›®æ ‡å’Œé‡Œç¨‹ç¢‘
2. **ç»“æ„åˆç†**ï¼šæŒ‰ç…§å­¦ä¹ è¿›åº¦åˆç†å®‰æ’å†…å®¹
3. **æ—¶é—´è§„åˆ’**ï¼šæä¾›å…·ä½“çš„æ—¶é—´å®‰æ’å»ºè®®
4. **æ–¹æ³•æŒ‡å¯¼**ï¼šåŒ…å«å­¦ä¹ æ–¹æ³•å’ŒæŠ€å·§å»ºè®®
5. **å¯æ“ä½œæ€§**ï¼šè®¡åˆ’å…·ä½“å¯æ‰§è¡Œ

å½“å‰è®¾å®šéš¾åº¦ï¼š{difficulty_desc}

è¯·ä½¿ç”¨ä¸­æ–‡ï¼Œé‡‡ç”¨markdownæ ¼å¼ï¼Œç»“æ„åŒ–åœ°ç»„ç»‡å­¦ä¹ è®¡åˆ’ã€‚"""
                },
                {
                    "role": "user",
                    "content": f"""åŸºäºä»¥ä¸‹å­¦ä¹ ææ–™ï¼Œä¸º{difficulty_desc}çš„å­¦ä¹ è€…åˆ¶å®šè¯¦ç»†çš„å­¦ä¹ è®¡åˆ’ï¼š

{combined_content}

è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹éƒ¨åˆ†çš„å­¦ä¹ è®¡åˆ’ï¼š
1. å­¦ä¹ ç›®æ ‡
2. å†…å®¹æ¦‚è§ˆ
3. å­¦ä¹ é˜¶æ®µåˆ’åˆ†
4. å…·ä½“å­¦ä¹ å®‰æ’
5. å­¦ä¹ æ–¹æ³•å»ºè®®
6. è¯„ä¼°æ–¹å¼
7. æ³¨æ„äº‹é¡¹"""
                }
            ]
            
            result = self._call_llm(messages, use_deepseek, temperature=0.4, max_tokens=3000)
            
            if not result["success"]:
                return result
            
            return {
                "success": True,
                "study_plan": result["content"],
                "difficulty": difficulty,
                "model_used": result["model_used"],
                "document_count": len(documents)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"å­¦ä¹ è®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    def explain_concept(self, concept: str, use_deepseek: bool = False, session_id: str = None) -> Dict[str, Any]:
        """æ¦‚å¿µè§£é‡Šï¼ˆæ”¯æŒä¸Šä¸‹æ–‡ï¼‰"""
        try:
            # å¦‚æœæ²¡æœ‰æä¾›session_idï¼Œç”Ÿæˆä¸€ä¸ª
            if not session_id:
                session_id = str(uuid.uuid4())
            
            # æœç´¢ç›¸å…³æ–‡æ¡£
            relevant_docs = self.rag_service.search_similar_documents(concept, k=3)
            
            # æ„å»ºè§£é‡Šæ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä¸ªæ¦‚å¿µè§£é‡Šä¸“å®¶ï¼Œæ“…é•¿ç”¨æ¸…æ™°ã€æ˜“æ‡‚çš„æ–¹å¼è§£é‡Šå„ç§æ¦‚å¿µã€‚

è§£é‡Šè¦æ±‚ï¼š
1. **å®šä¹‰å‡†ç¡®**ï¼šç»™å‡ºæ¦‚å¿µçš„å‡†ç¡®å®šä¹‰
2. **é€šä¿—æ˜“æ‡‚**ï¼šç”¨ç®€å•çš„è¯­è¨€è§£é‡Šå¤æ‚æ¦‚å¿µ
3. **ä¸¾ä¾‹è¯´æ˜**ï¼šæä¾›å…·ä½“ä¾‹å­å¸®åŠ©ç†è§£
4. **å…³è”åˆ†æ**ï¼šè¯´æ˜ä¸å…¶ä»–æ¦‚å¿µçš„å…³ç³»
5. **å®é™…åº”ç”¨**ï¼šä»‹ç»æ¦‚å¿µçš„å®é™…åº”ç”¨åœºæ™¯

å¦‚æœä¹‹å‰çš„å¯¹è¯ä¸­æåˆ°è¿‡ç›¸å…³æ¦‚å¿µï¼Œè¦ä½“ç°å‡ºè¿ç»­æ€§å’Œå…³è”æ€§ã€‚
ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œç»“æ„æ¸…æ™°ï¼Œä¾¿äºç†è§£ã€‚"""
                }
            ]
            
            # æ·»åŠ å†å²å¯¹è¯ä¸Šä¸‹æ–‡
            if session_id:
                historical_messages = self.session_service.get_context_for_llm(session_id)
                if historical_messages:
                    messages.extend(historical_messages[-4:])  # åªå–æœ€è¿‘2è½®å¯¹è¯
            
            # æ„å»ºå½“å‰é—®é¢˜
            if relevant_docs:
                context_parts = []
                for doc in relevant_docs:
                    context_parts.append(doc["content"])
                context = "\n\n".join(context_parts)
                
                user_message = f"""è¯·è§£é‡Šä»¥ä¸‹æ¦‚å¿µï¼š{concept}

ç›¸å…³æ–‡æ¡£å†…å®¹ï¼š
{context}

è¯·åŸºäºæ–‡æ¡£å†…å®¹å’Œä½ çš„çŸ¥è¯†ï¼Œè¯¦ç»†è§£é‡Šè¿™ä¸ªæ¦‚å¿µã€‚"""
            else:
                user_message = f"""è¯·è¯¦ç»†è§£é‡Šä»¥ä¸‹æ¦‚å¿µï¼š{concept}

è¯·æä¾›ï¼š
1. æ¦‚å¿µå®šä¹‰
2. å…³é”®ç‰¹å¾
3. å…·ä½“ä¾‹å­
4. å®é™…åº”ç”¨
5. ç›¸å…³æ¦‚å¿µ"""
            
            messages.append({"role": "user", "content": user_message})
            
            # è°ƒç”¨LLM
            result = self._call_llm(messages, use_deepseek, temperature=0.3)
            
            if not result["success"]:
                return result
            
            # ä¿å­˜å¯¹è¯åˆ°ä¼šè¯å†å²
            self.session_service.add_conversation(
                session_id=session_id,
                question=f"è§£é‡Šæ¦‚å¿µï¼š{concept}",
                answer=result["content"],
                model_used=result["model_used"]
            )
            
            return {
                "success": True,
                "explanation": result["content"],
                "concept": concept,
                "model_used": result["model_used"],
                "has_context": len(relevant_docs) > 0,
                "session_id": session_id
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"æ¦‚å¿µè§£é‡Šå¤±è´¥: {str(e)}",
                "session_id": session_id
            }
    
    def get_session_info(self, session_id: str) -> Dict[str, Any]:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        return self.session_service.get_session_info(session_id)
    
    def clear_conversation_context(self, session_id: str) -> Dict[str, Any]:
        """æ¸…é™¤ä¼šè¯ä¸Šä¸‹æ–‡"""
        try:
            success = self.session_service.clear_session(session_id)
            
            if success:
                return {
                    "success": True,
                    "message": f"ä¼šè¯ {session_id} çš„ä¸Šä¸‹æ–‡å·²æ¸…é™¤"
                }
            else:
                return {
                    "success": False,
                    "error": "æ¸…é™¤ä¼šè¯ä¸Šä¸‹æ–‡å¤±è´¥"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"æ¸…é™¤ä¼šè¯ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}"
            }
    
    def get_service_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        try:
            session_status = self.session_service.get_health_status()
            
            return {
                "ai_service": {
                    "openai_available": self.openai_client is not None,
                    "deepseek_available": self.deepseek_client is not None
                },
                "session_service": session_status,
                "rag_service": {
                    "document_count": len(self.rag_service.list_documents())
                }
            }
            
        except Exception as e:
            return {
                "error": f"è·å–æœåŠ¡çŠ¶æ€å¤±è´¥: {str(e)}"
            }
    
    def _search_in_multiple_documents(self, question: str, document_ids: List[str], k: int = 5) -> List[Dict]:
        """åœ¨å¤šä¸ªæŒ‡å®šæ–‡æ¡£ä¸­æœç´¢ç›¸å…³å†…å®¹"""
        try:
            all_relevant_docs = []
            
            for document_id in document_ids:
                # æœç´¢æ¯ä¸ªæ–‡æ¡£
                docs_in_document = self._search_in_specific_document(question, document_id, k)
                all_relevant_docs.extend(docs_in_document)
            
            # æŒ‰ç›¸å…³æ€§æ’åºï¼Œå–å‰kä¸ª
            all_relevant_docs.sort(key=lambda x: x.get("score", 0), reverse=True)
            return all_relevant_docs[:k]
            
        except Exception as e:
            print(f"å¤šæ–‡æ¡£æœç´¢é”™è¯¯: {str(e)}")
            return []
    
    def _search_in_specific_document(self, question: str, document_id: str, k: int = 5) -> List[Dict]:
        """åœ¨æŒ‡å®šæ–‡æ¡£ä¸­æœç´¢ç›¸å…³å†…å®¹"""
        try:
            # è·å–æŒ‡å®šæ–‡æ¡£çš„æ‰€æœ‰å†…å®¹
            document_contents = self.rag_service.get_documents_by_id(document_id)
            
            if not document_contents:
                return []
            
            # ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼ˆä½ ä¹Ÿå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç›¸ä¼¼æ€§æœç´¢ï¼‰
            relevant_docs = []
            for doc in document_contents:
                # è®¡ç®—ç®€å•çš„ç›¸å…³æ€§å¾—åˆ†
                content = doc["content"].lower()
                question_lower = question.lower()
                
                # åŸºäºå…³é”®è¯å‡ºç°æ¬¡æ•°è®¡ç®—åˆ†æ•°
                score = 0
                for word in question_lower.split():
                    if len(word) > 1:  # å¿½ç•¥å¤ªçŸ­çš„è¯
                        score += content.count(word)
                
                if score > 0:
                    relevant_docs.append({
                        "content": doc["content"],
                        "metadata": doc["metadata"],
                        "score": score
                    })
            
            # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›å‰kä¸ª
            relevant_docs.sort(key=lambda x: x["score"], reverse=True)
            return relevant_docs[:k]
            
        except Exception as e:
            print(f"å•æ–‡æ¡£æœç´¢é”™è¯¯: {str(e)}")
            return [] 